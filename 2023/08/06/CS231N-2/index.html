<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/hexo_blog/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/hexo_blog/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/hexo_blog/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/hexo_blog/images/logo.svg" color="#222">

<link rel="stylesheet" href="/hexo_blog/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"xu-liyi.github.io","root":"/hexo_blog/","images":"/hexo_blog/images","scheme":"Gemini","darkmode":true,"version":"8.17.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}}</script><script src="/hexo_blog/js/config.js"></script>

    <meta name="description" content="10 Recurrent Neural Networks 处理序列相关的数据类型，如Image Captioning：image -&gt; sequence of words 非序列数据的顺序，如分类和生成。 RNN到底是什么？接收输入x，内部隐藏态(internal hidden state)会在每次读取新的输入时更新，每一个时间步，都会有一个输出。 (Vanilla) Recurrent N">
<meta property="og:type" content="article">
<meta property="og:title" content="CS231N笔记-下">
<meta property="og:url" content="https://xu-liyi.github.io/hexo_blog/2023/08/06/CS231N-2/index.html">
<meta property="og:site_name" content="Entropy">
<meta property="og:description" content="10 Recurrent Neural Networks 处理序列相关的数据类型，如Image Captioning：image -&gt; sequence of words 非序列数据的顺序，如分类和生成。 RNN到底是什么？接收输入x，内部隐藏态(internal hidden state)会在每次读取新的输入时更新，每一个时间步，都会有一个输出。 (Vanilla) Recurrent N">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://xu-liyi.github.io/hexo_blog/2023/08/06/CS231N-2/image-20230726151554029.png">
<meta property="og:image" content="https://xu-liyi.github.io/hexo_blog/2023/08/06/CS231N-2/image-20230726194934257.png">
<meta property="og:image" content="https://xu-liyi.github.io/hexo_blog/2023/08/06/CS231N-2/image-20230726200453494.png">
<meta property="og:image" content="https://xu-liyi.github.io/hexo_blog/2023/08/06/CS231N-2/image-20230726203437451.png">
<meta property="og:image" content="https://xu-liyi.github.io/hexo_blog/2023/08/06/CS231N-2/image-20230726213326934.png">
<meta property="og:image" content="https://xu-liyi.github.io/hexo_blog/2023/08/06/CS231N-2/image-20230726210019443.png">
<meta property="og:image" content="https://xu-liyi.github.io/hexo_blog/2023/08/06/CS231N-2/image-20230726214038472.png">
<meta property="og:image" content="https://xu-liyi.github.io/hexo_blog/2023/08/06/CS231N-2/image-20230727101411346.png">
<meta property="og:image" content="https://xu-liyi.github.io/hexo_blog/2023/08/06/CS231N-2/image-20230727103650503.png">
<meta property="og:image" content="https://xu-liyi.github.io/hexo_blog/2023/08/06/CS231N-2/image-20230727175723039.png">
<meta property="og:image" content="https://xu-liyi.github.io/hexo_blog/2023/08/06/CS231N-2/image-20230727201506622.png">
<meta property="og:image" content="https://xu-liyi.github.io/hexo_blog/2023/08/06/CS231N-2/image-20230727204646166.png">
<meta property="og:image" content="https://xu-liyi.github.io/hexo_blog/2023/08/06/CS231N-2/image-20230727211159481.png">
<meta property="og:image" content="https://xu-liyi.github.io/hexo_blog/2023/08/06/CS231N-2/image-20230727213058949.png">
<meta property="og:image" content="https://xu-liyi.github.io/hexo_blog/2023/08/06/CS231N-2/image-20230727213457036.png">
<meta property="og:image" content="https://xu-liyi.github.io/hexo_blog/2023/08/06/CS231N-2/image-20230727213627047.png">
<meta property="og:image" content="https://xu-liyi.github.io/hexo_blog/2023/08/06/CS231N-2/image-20230728091654535.png">
<meta property="og:image" content="https://xu-liyi.github.io/hexo_blog/2023/08/06/CS231N-2/image-20230730161012468.png">
<meta property="og:image" content="https://xu-liyi.github.io/hexo_blog/2023/08/06/CS231N-2/image-20230730162624787.png">
<meta property="og:image" content="https://xu-liyi.github.io/hexo_blog/2023/08/06/CS231N-2/image-20230730171552564.png">
<meta property="og:image" content="https://xu-liyi.github.io/hexo_blog/2023/08/06/CS231N-2/image-20230730184126993.png">
<meta property="article:published_time" content="2023-08-06T07:06:57.048Z">
<meta property="article:modified_time" content="2023-08-06T07:23:17.846Z">
<meta property="article:author" content="xu liyi">
<meta property="article:tag" content="计算机视觉">
<meta property="article:tag" content="深度学习">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://xu-liyi.github.io/hexo_blog/2023/08/06/CS231N-2/image-20230726151554029.png">


<link rel="canonical" href="https://xu-liyi.github.io/hexo_blog/2023/08/06/CS231N-2/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"en","comments":true,"permalink":"https://xu-liyi.github.io/hexo_blog/2023/08/06/CS231N-2/","path":"2023/08/06/CS231N-2/","title":"CS231N笔记-下"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>CS231N笔记-下 | Entropy</title>
  








  <noscript>
    <link rel="stylesheet" href="/hexo_blog/css/noscript.css">
  </noscript>
<style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style></head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/hexo_blog/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Entropy</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/hexo_blog/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li><li class="menu-item menu-item-about"><a href="/hexo_blog/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a></li><li class="menu-item menu-item-tags"><a href="/hexo_blog/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a></li><li class="menu-item menu-item-archives"><a href="/hexo_blog/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a></li>
  </ul>
</nav>




</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#10-Recurrent-Neural-Networks"><span class="nav-number">1.</span> <span class="nav-text">10 Recurrent Neural Networks</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Vanilla-Recurrent-Neural-Network"><span class="nav-number">1.1.</span> <span class="nav-text">(Vanilla) Recurrent Neural Network</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%BC%A9%E7%9F%AD%E7%9A%84%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD-Truncated-Backpropagation-through"><span class="nav-number">1.1.1.</span> <span class="nav-text">缩短的反向传播(Truncated Backpropagation through)</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%9B%BE%E5%83%8F%E6%A0%87%E6%B3%A8%E6%A8%A1%E5%9E%8B"><span class="nav-number">1.2.</span> <span class="nav-text">图像标注模型</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6-Attention"><span class="nav-number">1.2.1.</span> <span class="nav-text">注意力机制(Attention)</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%A4%9A%E5%B1%82%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="nav-number">1.3.</span> <span class="nav-text">多层循环神经网络</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%A2%AF%E5%BA%A6%E6%B5%81%E5%87%BA%E7%8E%B0%E7%9A%84%E9%97%AE%E9%A2%98-Vanilla-RNN-Gradient-Flow"><span class="nav-number">1.4.</span> <span class="nav-text">梯度流出现的问题(Vanilla RNN Gradient Flow)</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%A2%AF%E5%BA%A6%E6%B6%88%E5%A4%B1%E5%92%8C%E6%A2%AF%E5%BA%A6%E7%88%86%E7%82%B8"><span class="nav-number">1.4.1.</span> <span class="nav-text">梯度消失和梯度爆炸</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Long-Short-Term-Memory-LSTM"><span class="nav-number">1.5.</span> <span class="nav-text">Long Short Term Memory(LSTM)</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#LSTM%E6%A2%AF%E5%BA%A6%E6%B5%81"><span class="nav-number">1.5.1.</span> <span class="nav-text">LSTM梯度流</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#11-Detection-and-Segmentation"><span class="nav-number">2.</span> <span class="nav-text">11 Detection and Segmentation</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2-Semantic-Segmentation"><span class="nav-number">2.1.</span> <span class="nav-text">语义分割(Semantic Segmentation)</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3-Sliding-Window"><span class="nav-number">2.1.1.</span> <span class="nav-text">滑动窗口(Sliding Window)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%85%A8%E5%8D%B7%E7%A7%AF-Fully-Convolutional"><span class="nav-number">2.1.2.</span> <span class="nav-text">全卷积(Fully Convolutional)</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Classification-Localization-%E5%88%86%E7%B1%BB-%E5%AE%9A%E4%BD%8D"><span class="nav-number">2.2.</span> <span class="nav-text">Classification+Localization(分类+定位)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Object-Detection-%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B"><span class="nav-number">2.3.</span> <span class="nav-text">Object Detection(目标检测)</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3-Sliding-Window-1"><span class="nav-number">2.3.1.</span> <span class="nav-text">滑动窗口(Sliding Window)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%80%99%E9%80%89%E5%8C%BA%E5%9F%9F-Region-Proposals"><span class="nav-number">2.3.2.</span> <span class="nav-text">候选区域(Region Proposals)</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%8D%E4%BD%BF%E7%94%A8%E5%80%99%E9%80%89%E5%8C%BA%E5%9F%9F%E7%9A%84%E6%A3%80%E6%B5%8B%E6%96%B9%E6%B3%95%EF%BC%9AYOLO-SSD"><span class="nav-number">2.4.</span> <span class="nav-text">不使用候选区域的检测方法：YOLO&#x2F;SSD</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#YOLO"><span class="nav-number">2.4.1.</span> <span class="nav-text">YOLO</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Instance-Segmentation-%E7%89%A9%E4%BD%93%E5%88%86%E5%89%B2"><span class="nav-number">2.5.</span> <span class="nav-text">Instance Segmentation(物体分割)</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Mask-R-CNN"><span class="nav-number">2.5.1.</span> <span class="nav-text">Mask R-CNN</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#12-Visualizing-and-Understanding"><span class="nav-number">3.</span> <span class="nav-text">12 Visualizing and Understanding</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#First-Layer-Visualize-Filters"><span class="nav-number">3.1.</span> <span class="nav-text">First Layer: Visualize Filters</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Last-Layer-Nearest-Neighbors"><span class="nav-number">3.2.</span> <span class="nav-text">Last Layer: Nearest Neighbors</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Maximally-Activating-Paches"><span class="nav-number">3.3.</span> <span class="nav-text">Maximally Activating Paches</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%81%AE%E6%8C%A1%E5%AE%9E%E9%AA%8C-Occlusion-Experiments"><span class="nav-number">3.4.</span> <span class="nav-text">遮挡实验(Occlusion Experiments)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Saliency-Maps-%E6%98%BE%E8%91%97%E5%9B%BE"><span class="nav-number">3.5.</span> <span class="nav-text">Saliency Maps(显著图)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#guided-backprop-%E5%BC%95%E5%AF%BC%E5%BC%8F%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD"><span class="nav-number">3.6.</span> <span class="nav-text">guided backprop(引导式反向传播)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Gradient-Ascent"><span class="nav-number">3.7.</span> <span class="nav-text">Gradient Ascent</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Fooling-Images"><span class="nav-number">3.8.</span> <span class="nav-text">Fooling Images</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#DeepDream-Amplify-existing-features"><span class="nav-number">3.9.</span> <span class="nav-text">DeepDream: Amplify existing features</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%89%B9%E5%BE%81%E5%8F%8D%E6%BC%94-Feature-Inversion"><span class="nav-number">3.10.</span> <span class="nav-text">特征反演(Feature Inversion)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%BA%B9%E7%90%86%E5%90%88%E6%88%90-Texture-Synthesis"><span class="nav-number">3.11.</span> <span class="nav-text">纹理合成(Texture Synthesis)</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%BD%91%E7%BB%9C%E7%BA%B9%E7%90%86%E7%94%9F%E6%88%90-Neural-Texture-Synthesis-Gram-Matrix"><span class="nav-number">3.11.1.</span> <span class="nav-text">网络纹理生成(Neural Texture Synthesis): Gram Matrix</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Neural-Style-Transfer"><span class="nav-number">3.11.2.</span> <span class="nav-text">Neural Style Transfer</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Fast-Style-Transfer"><span class="nav-number">3.11.3.</span> <span class="nav-text">Fast Style Transfer</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#13-Generative-Models"><span class="nav-number">4.</span> <span class="nav-text">13 Generative Models</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-Unsupervised-Learning"><span class="nav-number">4.1.</span> <span class="nav-text">无监督学习(Unsupervised Learning)</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B"><span class="nav-number">4.1.1.</span> <span class="nav-text">生成模型</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B%E5%88%86%E7%B1%BB"><span class="nav-number">4.2.</span> <span class="nav-text">生成模型分类</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Pixel-RNN-CNN"><span class="nav-number">4.3.</span> <span class="nav-text">Pixel RNN&#x2F;CNN</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#PixelRNN"><span class="nav-number">4.3.1.</span> <span class="nav-text">PixelRNN</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#PixelCNN"><span class="nav-number">4.3.2.</span> <span class="nav-text">PixelCNN</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Variational-Autoencoder-VAE"><span class="nav-number">4.4.</span> <span class="nav-text">Variational Autoencoder(VAE)</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Autoencoders"><span class="nav-number">4.4.1.</span> <span class="nav-text">Autoencoders</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Variational-Autoencoder"><span class="nav-number">4.4.2.</span> <span class="nav-text">Variational  Autoencoder</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Generative-Adversarial-Networks-GAN"><span class="nav-number">4.5.</span> <span class="nav-text">Generative Adversarial Networks(GAN)</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Training-GANs-Two-player-game"><span class="nav-number">4.5.1.</span> <span class="nav-text">Training GANs: Two-player game</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#14-Deep-Reinforcement-Learning"><span class="nav-number">5.</span> <span class="nav-text">14 Deep Reinforcement Learning</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E5%86%B3%E7%AD%96%E8%BF%87%E7%A8%8B-Markov-Decision-Process"><span class="nav-number">5.1.</span> <span class="nav-text">马尔可夫决策过程(Markov Decision Process)</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Q-learning"><span class="nav-number">5.1.1.</span> <span class="nav-text">Q-learning</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Policy-Gradients"><span class="nav-number">5.1.2.</span> <span class="nav-text">Policy Gradients</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#15-Efficient-Methods-and-Hardware-for-Deep-Learning"><span class="nav-number">6.</span> <span class="nav-text">15 Efficient Methods and Hardware for Deep Learning</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%AB%98%E6%95%88%E6%8E%A8%E6%96%AD%E7%AE%97%E6%B3%95-Algorithms-for-Efficient-Inference"><span class="nav-number">6.1.</span> <span class="nav-text">高效推断算法(Algorithms for Efficient Inference)</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Pruning-%E5%89%AA%E6%9E%9D"><span class="nav-number">6.1.1.</span> <span class="nav-text">Pruning(剪枝)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%9D%83%E5%80%BC%E5%85%B1%E4%BA%AB-weight-sharing"><span class="nav-number">6.1.2.</span> <span class="nav-text">权值共享(weight sharing)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Quantization-%E9%87%8F%E5%8C%96"><span class="nav-number">6.1.3.</span> <span class="nav-text">Quantization(量化)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BD%8E%E7%A7%A9%E8%BF%91%E4%BC%BC-Low-Rank-Approximation"><span class="nav-number">6.1.4.</span> <span class="nav-text">低秩近似(Low Rank Approximation)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Binary-Ternary-Net-Motivation"><span class="nav-number">6.1.5.</span> <span class="nav-text">Binary&#x2F;Ternary Net: Motivation</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Winograd-Transformation"><span class="nav-number">6.1.6.</span> <span class="nav-text">Winograd Transformation</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%AB%98%E6%95%88%E6%8E%A8%E6%96%AD%E7%A1%AC%E4%BB%B6-Hardware-for-Efficient-Inference"><span class="nav-number">6.2.</span> <span class="nav-text">高效推断硬件(Hardware for Efficient Inference)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%AB%98%E6%95%88%E8%AE%AD%E7%BB%83%E7%AE%97%E6%B3%95-Algorithms-for-Efficient-Training"><span class="nav-number">6.3.</span> <span class="nav-text">高效训练算法(Algorithms for Efficient Training)</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%B9%B6%E8%A1%8C%E5%8C%96-Parallelization"><span class="nav-number">6.3.1.</span> <span class="nav-text">并行化(Parallelization)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%B7%B7%E5%90%88%E7%B2%BE%E5%BA%A6%E8%AE%AD%E7%BB%83-Mixed-Precision-with-FP16-and-FP32"><span class="nav-number">6.3.2.</span> <span class="nav-text">混合精度训练(Mixed Precision with FP16 and FP32)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E7%B2%BE%E9%A6%8F-Model-Distillation"><span class="nav-number">6.3.3.</span> <span class="nav-text">模型精馏(Model Distillation)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AF%86-%E7%96%8F-%E5%AF%86%E8%AE%AD%E7%BB%83-Dende-Sparse-Dense-training-DSD"><span class="nav-number">6.3.4.</span> <span class="nav-text">密-疏-密训练(Dende-Sparse-Dense training, DSD)</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%AB%98%E6%95%88%E8%AE%AD%E7%BB%83%E7%A1%AC%E4%BB%B6-Hardware-for-Efficient-Training"><span class="nav-number">6.4.</span> <span class="nav-text">高效训练硬件(Hardware for Efficient Training)</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#GPUs-for-Training"><span class="nav-number">6.4.1.</span> <span class="nav-text">GPUs for Training</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#16-Adversarial-Examples-and-Adversarial-Training"><span class="nav-number">7.</span> <span class="nav-text">16 Adversarial Examples and Adversarial Training</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">xu liyi</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/hexo_blog/archives/">
          <span class="site-state-item-count">4</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/hexo_blog/tags/">
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="https://xu-liyi.github.io/hexo_blog/2023/08/06/CS231N-2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/hexo_blog/images/avatar.gif">
      <meta itemprop="name" content="xu liyi">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Entropy">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="CS231N笔记-下 | Entropy">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          CS231N笔记-下
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2023-08-06 15:06:57 / Modified: 15:23:17" itemprop="dateCreated datePublished" datetime="2023-08-06T15:06:57+08:00">2023-08-06</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><h1 id="10-Recurrent-Neural-Networks"><a href="#10-Recurrent-Neural-Networks" class="headerlink" title="10 Recurrent Neural Networks"></a>10 Recurrent Neural Networks</h1><p> 处理序列相关的数据类型，如Image Captioning：image -&gt; sequence of words</p>
<p>非序列数据的顺序，如分类和生成。</p>
<p>RNN到底是什么？接收输入x，内部隐藏态(internal hidden state)会在每次读取新的输入时更新，每一个时间步，都会有一个输出。<br><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="16.997ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 7512.7 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="210E" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path></g><g data-mml-node="mi" transform="translate(609,-150) scale(0.707)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g></g><g data-mml-node="mo" transform="translate(1192,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="msub" transform="translate(2247.8,0)"><g data-mml-node="mi"><path data-c="1D453" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path></g><g data-mml-node="mi" transform="translate(523,-150) scale(0.707)"><path data-c="1D44A" d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z"></path></g></g><g data-mml-node="mo" transform="translate(3561.9,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(3950.9,0)"><g data-mml-node="mi"><path data-c="210E" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path></g><g data-mml-node="TeXAtom" transform="translate(609,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(361,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(1139,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g><g data-mml-node="mo" transform="translate(5768.8,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="msub" transform="translate(6213.5,0)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mi" transform="translate(605,-150) scale(0.707)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g></g><g data-mml-node="mo" transform="translate(7123.7,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container></p>
<h2 id="Vanilla-Recurrent-Neural-Network"><a href="#Vanilla-Recurrent-Neural-Network" class="headerlink" title="(Vanilla) Recurrent Neural Network"></a>(Vanilla) Recurrent Neural Network</h2><p><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.667ex;" xmlns="http://www.w3.org/2000/svg" width="40.192ex" height="2.364ex" role="img" focusable="false" viewBox="0 -750 17764.7 1045"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="210E" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path></g><g data-mml-node="mi" transform="translate(609,-150) scale(0.707)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g></g><g data-mml-node="mo" transform="translate(1192,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(2247.8,0)"><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z"></path><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(389,0)"></path><path data-c="6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(889,0)"></path><path data-c="68" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 124T102 167T103 217T103 272T103 329Q103 366 103 407T103 482T102 542T102 586T102 603Q99 622 88 628T43 637H25V660Q25 683 27 683L37 684Q47 685 66 686T103 688Q120 689 140 690T170 693T181 694H184V367Q244 442 328 442Q451 442 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(1445,0)"></path></g><g data-mml-node="mo" transform="translate(4248.8,0)"><path data-c="2061" d=""></path></g><g data-mml-node="mo" transform="translate(4248.8,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(4637.8,0)"><g data-mml-node="mi"><path data-c="1D44A" d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z"></path></g><g data-mml-node="TeXAtom" transform="translate(977,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="210E" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path></g><g data-mml-node="mi" transform="translate(576,0)"><path data-c="210E" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path></g></g></g><g data-mml-node="msub" transform="translate(6479.4,0)"><g data-mml-node="mi"><path data-c="210E" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path></g><g data-mml-node="TeXAtom" transform="translate(609,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(361,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(1139,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g><g data-mml-node="mo" transform="translate(8519.6,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="msub" transform="translate(9519.8,0)"><g data-mml-node="mi"><path data-c="1D44A" d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z"></path></g><g data-mml-node="TeXAtom" transform="translate(977,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mi" transform="translate(572,0)"><path data-c="210E" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path></g></g></g><g data-mml-node="msub" transform="translate(11358.6,0)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mi" transform="translate(605,-150) scale(0.707)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g></g><g data-mml-node="mo" transform="translate(12268.8,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mtext" transform="translate(12657.8,0)"><path data-c="A0" d=""></path></g><g data-mml-node="msub" transform="translate(12907.8,0)"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(523,-150) scale(0.707)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g></g><g data-mml-node="mo" transform="translate(14013.9,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="msub" transform="translate(15069.6,0)"><g data-mml-node="mi"><path data-c="1D44A" d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z"></path></g><g data-mml-node="TeXAtom" transform="translate(977,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="210E" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path></g><g data-mml-node="mi" transform="translate(576,0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g></g></g><g data-mml-node="msub" transform="translate(16850.4,0)"><g data-mml-node="mi"><path data-c="210E" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path></g><g data-mml-node="mi" transform="translate(609,-150) scale(0.707)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g></g></g></g></svg></mjx-container></p>
<p><img src="/hexo_blog/2023/08/06/CS231N-2/image-20230726151554029.png" alt="image-20230726151554029"></p>
<ul>
<li>每个时间步都用着相同的权重矩阵，接收不同的h和x</li>
<li>在反向传播的时候，每一个时间步都会产生dloss和dW，最终反向传播的梯度是每个时间步梯度的和</li>
<li>最终的损失值是所有损失值的加和</li>
</ul>
<p>RNN类型：</p>
<ul>
<li>一对多(one to many)</li>
<li>多对一(many to one)</li>
<li>多对多(sequence to sequence)=多对一+一对多</li>
</ul>
<h3 id="缩短的反向传播-Truncated-Backpropagation-through"><a href="#缩短的反向传播-Truncated-Backpropagation-through" class="headerlink" title="缩短的反向传播(Truncated Backpropagation through)"></a>缩短的反向传播(Truncated Backpropagation through)</h3><p>在一段序列上进行前向传播和反向传播，而不是整个序列上。即将整个序列分段，每一段进行单独的正向传播和反向传播</p>
<p>本质上，RNN是在预测下一个字符的概率，并且取最大概率的字符。</p>
<h2 id="图像标注模型"><a href="#图像标注模型" class="headerlink" title="图像标注模型"></a>图像标注模型</h2><p>图像输入到CNN模型中，得到特征向量再放入RNN模型生成图像语义信息(标签)</p>
<p>如何停止生成？设定一个结束标志符，当生成它时就结束生成</p>
<h3 id="注意力机制-Attention"><a href="#注意力机制-Attention" class="headerlink" title="注意力机制(Attention)"></a>注意力机制(Attention)</h3><p><img src="/hexo_blog/2023/08/06/CS231N-2/image-20230726194934257.png" alt="image-20230726194934257"></p>
<ul>
<li>RNN的输出不再是单个的字符，而是一个位置的分布</li>
<li>第一个时间步只输出位置分布，并将这个分布重新输入到特征矩阵中</li>
<li>特征矩阵经过位置分布处理后生成z矩阵，作为输入放到下一个时间步中</li>
<li>从第二个时间步开始，输出除了位置分布外，还有词向量分布，以此类推</li>
</ul>
<p>从训练的过程中来看，神经网络会不断的在特征矩阵中转移注意力，并输出单词</p>
<span id="more"></span>

<h2 id="多层循环神经网络"><a href="#多层循环神经网络" class="headerlink" title="多层循环神经网络"></a>多层循环神经网络</h2><p>多层隐藏层，加深隐藏层会让模型表现更好。</p>
<p><img src="/hexo_blog/2023/08/06/CS231N-2/image-20230726200453494.png" alt="image-20230726200453494"></p>
<h2 id="梯度流出现的问题-Vanilla-RNN-Gradient-Flow"><a href="#梯度流出现的问题-Vanilla-RNN-Gradient-Flow" class="headerlink" title="梯度流出现的问题(Vanilla RNN Gradient Flow)"></a>梯度流出现的问题(Vanilla RNN Gradient Flow)</h2><h3 id="梯度消失和梯度爆炸"><a href="#梯度消失和梯度爆炸" class="headerlink" title="梯度消失和梯度爆炸"></a>梯度消失和梯度爆炸</h3><p><img src="/hexo_blog/2023/08/06/CS231N-2/image-20230726203437451.png" alt="image-20230726203437451"></p>
<p>图中红色的路径是梯度计算的路径，不难看出，如果时间步非常大的话，根据链式法则，梯度的乘法会变得非常多。这是一件很糟糕的事情，如果乘法路径中多是小于1的数值，则梯度会逐渐趋向于消失，反之梯度会趋向于爆炸。</p>
<p>一种处理方法是做梯度截断，即判断梯度的范数超过一个阈值后，就将梯度乘并除一个值。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">grad_norm = np.<span class="built_in">sum</span>(grad * grad)</span><br><span class="line"><span class="keyword">if</span> grad_norm &gt; threshold:</span><br><span class="line">    grad *= (threshold / grad_norm)</span><br></pre></td></tr></table></figure>

<h2 id="Long-Short-Term-Memory-LSTM"><a href="#Long-Short-Term-Memory-LSTM" class="headerlink" title="Long Short Term Memory(LSTM)"></a>Long Short Term Memory(LSTM)</h2><p>思想起源于1997，增加了门控和细胞的概念</p>
<ul>
<li>f: Forget gate, Whether to erase cell</li>
<li>i: Input gate, whether to write to cell</li>
<li>g: Gate gate, How much to write to cell</li>
<li>o: Output gate, how much to reveal cell</li>
</ul>
<p>具体运算可以参考下面的图解</p>
<p><img src="/hexo_blog/2023/08/06/CS231N-2/image-20230726213326934.png" alt="image-20230726213326934"></p>
<ul>
<li>4h×2h的意思是将x和h横向堆起来，这代表2h；4h是说每一个h用来计算一个门(i, f, o, g)</li>
</ul>
<p><img src="/hexo_blog/2023/08/06/CS231N-2/image-20230726210019443.png" alt="image-20230726210019443"></p>
<h3 id="LSTM梯度流"><a href="#LSTM梯度流" class="headerlink" title="LSTM梯度流"></a>LSTM梯度流</h3><p><img src="/hexo_blog/2023/08/06/CS231N-2/image-20230726214038472.png" alt="image-20230726214038472"></p>
<p>简单来讲，计算c和h的梯度，就能算出w的局部梯度</p>
<p>高速公路网络：概念介于LSTM和残差网络之间</p>
<h1 id="11-Detection-and-Segmentation"><a href="#11-Detection-and-Segmentation" class="headerlink" title="11 Detection and Segmentation"></a>11 Detection and Segmentation</h1><h2 id="语义分割-Semantic-Segmentation"><a href="#语义分割-Semantic-Segmentation" class="headerlink" title="语义分割(Semantic Segmentation)"></a>语义分割(Semantic Segmentation)</h2><p>把每个像素分类到对应的的标签</p>
<h3 id="滑动窗口-Sliding-Window"><a href="#滑动窗口-Sliding-Window" class="headerlink" title="滑动窗口(Sliding Window)"></a>滑动窗口(Sliding Window)</h3><p>将输入的图像，打碎为许多小的，局部的图像块。再将图像块的中心像素分类</p>
<h3 id="全卷积-Fully-Convolutional"><a href="#全卷积-Fully-Convolutional" class="headerlink" title="全卷积(Fully Convolutional)"></a>全卷积(Fully Convolutional)</h3><p><img src="/hexo_blog/2023/08/06/CS231N-2/image-20230727101411346.png" alt="image-20230727101411346"></p>
<p>使用卷积神经网络，最终生成C*H*W的评分张量，其中，C是类的数量。最终生成分割的图像矩阵。这种网络的缺点是计算量太大。因此可以做如下改进：</p>
<p><img src="/hexo_blog/2023/08/06/CS231N-2/image-20230727103650503.png" alt="image-20230727103650503"></p>
<p>在神经网络内部做下采样(downsampling)和上采样(upsampling)，但会导致每层的清晰度减少。</p>
<p>上采样的方法：</p>
<ol>
<li><p>去池化(Unpooling)</p>
<ol>
<li>最近邻：将每个特征复制几份放到对应的位置上</li>
<li>“Bed of Nails”钉床函数：将上采样对应的空闲位置补0</li>
<li>“Max Unpooling”最大去池化：上采样放的对应元素位置是下采样最大池化的位置</li>
</ol>
</li>
<li><p>可学习的上采样：</p>
<ol>
<li>转置卷积(Transpose Convolution)、去卷积：大意应该是设置一个卷积核，和小矩阵的值分别乘卷积核对应的值后放到对应的大矩阵中，重叠的部分做求和处理</li>
</ol>
</li>
</ol>
<h2 id="Classification-Localization-分类-定位"><a href="#Classification-Localization-分类-定位" class="headerlink" title="Classification+Localization(分类+定位)"></a>Classification+Localization(分类+定位)</h2><p>基本思路：将图片放到深度学习网络中提取特征向量，然后将提取到的特征向量用两个不同的全连接层分别连接到分类得分向量和识别坐标向量。对于不同的任务，我们设置不同的损失函数，分类任务设置Softmax Loss，定位任务设置L2 Loss。这两个损失函数在反向传播时要做加权求和处理，权值的分配涉及一个超参数。</p>
<p><img src="/hexo_blog/2023/08/06/CS231N-2/image-20230727175723039.png" alt="image-20230727175723039"></p>
<h2 id="Object-Detection-目标检测"><a href="#Object-Detection-目标检测" class="headerlink" title="Object Detection(目标检测)"></a>Object Detection(目标检测)</h2><p>根据输入的对象，每当在图像中出现其中一类对象时，围绕对象划定一个框，并预测对象从属的类别。与上一节分类+定位的区别在于，目标检测无法预知对象的数量，即一张图片中有几个对象</p>
<h3 id="滑动窗口-Sliding-Window-1"><a href="#滑动窗口-Sliding-Window-1" class="headerlink" title="滑动窗口(Sliding Window)"></a>滑动窗口(Sliding Window)</h3><p>将输入图像切分为小块(crop)，并将小块输入到卷积神经网络中，只有网络会根据输入的小块进行分类决策。窗口不断滑动，不断产生分类。</p>
<p>问题：每个对象的尺寸都不一样，需要去不断尝试窗口大小，计算复杂度很高。</p>
<p>实践中已被淘汰。</p>
<h3 id="候选区域-Region-Proposals"><a href="#候选区域-Region-Proposals" class="headerlink" title="候选区域(Region Proposals)"></a>候选区域(Region Proposals)</h3><p>先将图像分割为上千个块，找出可能的候选区域，再将候选区域放到神经网络中</p>
<p><strong>R-CNN</strong></p>
<p><img src="/hexo_blog/2023/08/06/CS231N-2/image-20230727201506622.png" alt="image-20230727201506622"></p>
<p>将分出的候选区域变换到同一尺寸，放到卷积神经网络中，再经过SVM分类。</p>
<p>问题：</p>
<ul>
<li>每个区域都要训练，消耗大量算力</li>
<li>用固定的区域选择模型，并不学习参数</li>
<li>训练很慢，要将所有特征存入硬盘；测试阶段也很慢</li>
</ul>
<p><strong>Fast R-CNN</strong></p>
<p>将整个图像放入CNN中训练，得到整个图像的高分辨率特征图。然后使用修正过的候选区域算法，如选择搜索(Selective Search)，而不是针对备选区域切分图像的像素。之后考虑将候选区域投影到卷积特征图上，并从卷积特征图上提取块。这样做可以重用很多卷积计算。</p>
<p>得到的卷积特征块的尺寸是不一样的，因此还需要一个”Rol Pooling”层来将特征块整形到一致的尺寸。最后将重整后的特征块放到全连接层输出特征向量并使用分类器分类和预测定位区域：</p>
<p><img src="/hexo_blog/2023/08/06/CS231N-2/image-20230727204646166.png" alt="image-20230727204646166"></p>
<p>Fast R-CNN算法很快，训练时间比R-CNN几乎块10倍，测试时间快20倍</p>
<p>Fast R-CNN大部分时间还是浪费在找备选区域上。</p>
<p><strong>Faster R-CNN</strong></p>
<p>使用CNN做候选区域分割！</p>
<p>在Fast R-CNN的feature map基础上，增加一层Region Proposal Network(RPN)来预测特征的候选区域</p>
<p>整个网络有4个损失函数：</p>
<ul>
<li>RPN分类，区域有无目标对象</li>
<li>RPN回归，区域坐标</li>
<li>最终的分类得分</li>
<li>最终的对象区域</li>
</ul>
<p><img src="/hexo_blog/2023/08/06/CS231N-2/image-20230727211159481.png" alt="image-20230727211159481"></p>
<p>在测试集上的性能比Fast R-CNN还要快10倍</p>
<h2 id="不使用候选区域的检测方法：YOLO-SSD"><a href="#不使用候选区域的检测方法：YOLO-SSD" class="headerlink" title="不使用候选区域的检测方法：YOLO/SSD"></a>不使用候选区域的检测方法：YOLO/SSD</h2><p>YOLO：You Only Look Once</p>
<p>SSD：Single Shot Detection</p>
<h3 id="YOLO"><a href="#YOLO" class="headerlink" title="YOLO"></a>YOLO</h3><p>将图像划分成网格，在每个网格单元：</p>
<ul>
<li>预测(regress)base boxes(B)到final box的5个数值：(dx, dy, dh, dw, confidence)，confidence表示置信度</li>
<li>预测(predict)每一个分类(C)的分数，包括背景也作为一个分类</li>
<li>输出大小grid*grid*(5*B + C)的张量</li>
</ul>
<p><img src="/hexo_blog/2023/08/06/CS231N-2/image-20230727213058949.png" alt="image-20230727213058949"></p>
<h2 id="Instance-Segmentation-物体分割"><a href="#Instance-Segmentation-物体分割" class="headerlink" title="Instance Segmentation(物体分割)"></a>Instance Segmentation(物体分割)</h2><p>与语义分割的区别在于，物体分割可以得到像素级的精确分割</p>
<p><img src="/hexo_blog/2023/08/06/CS231N-2/image-20230727213457036.png" alt="image-20230727213457036"></p>
<h3 id="Mask-R-CNN"><a href="#Mask-R-CNN" class="headerlink" title="Mask R-CNN"></a>Mask R-CNN</h3><p><img src="/hexo_blog/2023/08/06/CS231N-2/image-20230727213627047.png" alt="image-20230727213627047"></p>
<p>类似faster R-CNN，将图像送入卷积神经网络，训练出特征图后再做候选区域(Rol Align)分割并对齐，分割出的候选区域预测分类和候选框(Box coordinates)，最后将候选框预测mask矩阵</p>
<p>只需再增加一个分支即可做姿态估计！</p>
<h1 id="12-Visualizing-and-Understanding"><a href="#12-Visualizing-and-Understanding" class="headerlink" title="12 Visualizing and Understanding"></a>12 Visualizing and Understanding</h1><h2 id="First-Layer-Visualize-Filters"><a href="#First-Layer-Visualize-Filters" class="headerlink" title="First Layer: Visualize Filters"></a>First Layer: Visualize Filters</h2><p><img src="/hexo_blog/2023/08/06/CS231N-2/image-20230728091654535.png" alt="image-20230728091654535"></p>
<p>大多是有向边和相反的颜色，这也符合人类视觉的规律</p>
<p>第二层和第三层可视化并没有直观的图像 </p>
<h2 id="Last-Layer-Nearest-Neighbors"><a href="#Last-Layer-Nearest-Neighbors" class="headerlink" title="Last Layer: Nearest Neighbors"></a>Last Layer: Nearest Neighbors</h2><p>最后一层指的是全连接层最后连接的特征向量。我们可以计算特征向量的最近邻，发现特征向量接近的图像往往都很相似。</p>
<p>t-SNE是一种经常在深度学习可视化中使用的降维方法，可以将最后一层的高维特征向量压缩到二维平面</p>
<h2 id="Maximally-Activating-Paches"><a href="#Maximally-Activating-Paches" class="headerlink" title="Maximally Activating Paches"></a>Maximally Activating Paches</h2><p>大意是追踪中间层的最大激活值对应的输入图像区域，运行了大量图片后会发现中间层不同神经元所对应的图像区域中所含的信息是差不多的，比如眼睛、字符等。</p>
<h2 id="遮挡实验-Occlusion-Experiments"><a href="#遮挡实验-Occlusion-Experiments" class="headerlink" title="遮挡实验(Occlusion Experiments)"></a>遮挡实验(Occlusion Experiments)</h2><p>遮挡图像的不同部位再放入神经网络中预测分类，寻找使预测分数降低最大的遮挡部位，可以证明这是神经网络所寻找的重要特征，对分类决策起重要作用</p>
<h2 id="Saliency-Maps-显著图"><a href="#Saliency-Maps-显著图" class="headerlink" title="Saliency Maps(显著图)"></a>Saliency Maps(显著图)</h2><p>计算分数对input的梯度，反应了如果对输入的像素做小小的扰动，预测分数会有多大的变化。这反映了像素对结果的重要性</p>
<h2 id="guided-backprop-引导式反向传播"><a href="#guided-backprop-引导式反向传播" class="headerlink" title="guided backprop(引导式反向传播)"></a>guided backprop(引导式反向传播)</h2><p>通过引导式反向传播来了解图像中的那个部分影响了神经元的分值</p>
<h2 id="Gradient-Ascent"><a href="#Gradient-Ascent" class="headerlink" title="Gradient Ascent"></a>Gradient Ascent</h2><p>生成一个最大激活神经元的图片</p>
<h2 id="Fooling-Images"><a href="#Fooling-Images" class="headerlink" title="Fooling Images"></a>Fooling Images</h2><p>输入一张图片，并告诉神经网络一个错误的标签，让神经网络优化图片直到符合这个标签。</p>
<p>会发现处理后的图片和之前的图片在肉眼上没有不同，像素级对比也是一堆噪声。但处理后的图片确实会被分到指定的错误类中</p>
<h2 id="DeepDream-Amplify-existing-features"><a href="#DeepDream-Amplify-existing-features" class="headerlink" title="DeepDream: Amplify existing features"></a>DeepDream: Amplify existing features</h2><p>不是通过最大化指定神经元生成图像，而是尝试去放大网络中一些层的激活值。</p>
<p>过程：选择一个图像和CNN的一层，反复运行：</p>
<ol>
<li>前向传播：计算选定层的激活值</li>
<li>设定选定层的梯度等于它的激活值</li>
<li>反向传播：计算图像的梯度</li>
<li>更新图像</li>
</ol>
<h2 id="特征反演-Feature-Inversion"><a href="#特征反演-Feature-Inversion" class="headerlink" title="特征反演(Feature Inversion)"></a>特征反演(Feature Inversion)</h2><p>选取一张图像，通过神经网络运行该图像，记录其中一个图像的特征值。然后根据它的特征表示重构那个图像。基于重建图像的样子可以给一些从该特征向量中捕获的图像类型的信息。使用的方法是最小化特征向量之间的距离</p>
<h2 id="纹理合成-Texture-Synthesis"><a href="#纹理合成-Texture-Synthesis" class="headerlink" title="纹理合成(Texture Synthesis)"></a>纹理合成(Texture Synthesis)</h2><p>基于一小块纹理的样本，生成一个有此纹理的更大的图像</p>
<h3 id="网络纹理生成-Neural-Texture-Synthesis-Gram-Matrix"><a href="#网络纹理生成-Neural-Texture-Synthesis-Gram-Matrix" class="headerlink" title="网络纹理生成(Neural Texture Synthesis): Gram Matrix"></a>网络纹理生成(Neural Texture Synthesis): Gram Matrix</h3><p>CNN的每一层可以得到一个C×H×W的特征张量，通过某种方式得到C*C的gram矩阵。</p>
<p>…（听不懂）</p>
<h3 id="Neural-Style-Transfer"><a href="#Neural-Style-Transfer" class="headerlink" title="Neural Style Transfer"></a>Neural Style Transfer</h3><p>将两张图像作为输入图像，将一张图像作为内容图像(Content Image)负责引导图像主体，另一张作为风格图像(Style Image)负责生成图像的纹理或风格，然后共同做特征识别。最小化内容图像的特征重构损失(feature reconstruction loss以及风格图像的格拉姆矩阵损失(gram matrix loss)</p>
<p>调整风格图像的大小可以改变不同的特征风格</p>
<p>问题：需要消耗大量的算力和内存，很慢</p>
<h3 id="Fast-Style-Transfer"><a href="#Fast-Style-Transfer" class="headerlink" title="Fast Style Transfer"></a>Fast Style Transfer</h3><ol>
<li>为每种风格训练一个前馈网络(feedforward net)</li>
<li>使用预训练CNN来计算内容图像和风格图像的损失，使用相同的梯度来更新前馈网络权重</li>
<li>训练后，使用一个单独的前向传播转换风格</li>
</ol>
<h1 id="13-Generative-Models"><a href="#13-Generative-Models" class="headerlink" title="13 Generative Models"></a>13 Generative Models</h1><h2 id="无监督学习-Unsupervised-Learning"><a href="#无监督学习-Unsupervised-Learning" class="headerlink" title="无监督学习(Unsupervised Learning)"></a>无监督学习(Unsupervised Learning)</h2><p>Data: x，不需要标签</p>
<p>Goal: 学习一些数据的重要隐藏结构</p>
<p>Examples：聚类、降维、特征学习、密度估计等</p>
<h3 id="生成模型"><a href="#生成模型" class="headerlink" title="生成模型"></a>生成模型</h3><p>生成模型也是无监督学习。</p>
<p>目标是学习一个模型<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="8.929ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 3946.7 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D443" d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z"></path></g><g data-mml-node="TeXAtom" transform="translate(675,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(878,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(1363,0)"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mi" transform="translate(1883,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(2349,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g></g></g><g data-mml-node="mo" transform="translate(2596.7,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(2985.7,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(3557.7,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container>相似于训练数据<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="7.797ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 3446.1 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D443" d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z"></path></g><g data-mml-node="TeXAtom" transform="translate(675,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mi" transform="translate(520,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mi" transform="translate(1049,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(1410,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g></g></g><g data-mml-node="mo" transform="translate(2096.1,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(2485.1,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(3057.1,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container>。</p>
<p>生成模型可以解决密度估计的问题</p>
<ul>
<li>显式密度估计(Explicit density estimation)：明确的定义并求解出目标模型p-model</li>
<li>隐式密度估计(Implicit denity estimation)：学习一个可以从p-model中生成样本的模型而不需要显式地定义它</li>
</ul>
<h2 id="生成模型分类"><a href="#生成模型分类" class="headerlink" title="生成模型分类"></a>生成模型分类</h2><p>生成模型(✅表示本节涉及的模型)</p>
<ul>
<li>显式密度模型<ul>
<li>可处理密度模型(Tractable density): Fully Visisble Belief Nets(完全可见信念网)<ul>
<li>NADE</li>
<li>MADE</li>
<li>PixelRNN/CNN✅</li>
</ul>
</li>
<li>近似密度模型(Approximate density)<ul>
<li>Variational: Variational Autoencoder✅</li>
<li>Markov Chain: Markov Chain: Boltzmann Machine</li>
</ul>
</li>
</ul>
</li>
<li>隐式密度模型<ul>
<li>Direct: GAN✅</li>
<li>Markov Chain: GSN</li>
</ul>
</li>
</ul>
<h2 id="Pixel-RNN-CNN"><a href="#Pixel-RNN-CNN" class="headerlink" title="Pixel RNN/CNN"></a>Pixel RNN/CNN</h2><p>使用链式法则分解image x的可能性，变成一维分布的乘积<br><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -2.819ex;" xmlns="http://www.w3.org/2000/svg" width="29.316ex" height="6.354ex" role="img" focusable="false" viewBox="0 -1562.5 12957.6 2808.5"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(536,-150) scale(0.707)"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g></g><g data-mml-node="mo" transform="translate(917.6,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(1306.6,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(1878.6,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(2545.4,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="munderover" transform="translate(3601.2,0)"><g data-mml-node="mo"><path data-c="220F" d="M220 812Q220 813 218 819T214 829T208 840T199 853T185 866T166 878T140 887T107 893T66 896H56V950H1221V896H1211Q1080 896 1058 812V-311Q1076 -396 1211 -396H1221V-450H725V-396H735Q864 -396 888 -314Q889 -312 889 -311V896H388V292L389 -311Q405 -396 542 -396H552V-450H56V-396H66Q195 -396 219 -314Q220 -312 220 -311V812Z"></path></g><g data-mml-node="TeXAtom" transform="translate(65.2,-1087.9) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(345,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(1123,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mi" transform="translate(426.9,1150) scale(0.707)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="msub" transform="translate(5045.9,0)"><g data-mml-node="mi"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(536,-150) scale(0.707)"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g></g><g data-mml-node="mo" transform="translate(5963.5,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(6352.5,0)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mi" transform="translate(605,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(7251.4,0) translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path></g><g data-mml-node="msub" transform="translate(7529.4,0)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mn" transform="translate(605,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mo" transform="translate(8538,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mo" transform="translate(8982.7,0)"><path data-c="2026" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60ZM525 60Q525 84 542 102T585 120Q609 120 627 104T646 61Q646 36 629 18T586 0T543 17T525 60ZM972 60Q972 84 989 102T1032 120Q1056 120 1074 104T1093 61Q1093 36 1076 18T1033 0T990 17T972 60Z"></path></g><g data-mml-node="mo" transform="translate(10321.3,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="msub" transform="translate(10766,0)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="TeXAtom" transform="translate(605,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(345,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(1123,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g><g data-mml-node="mo" transform="translate(12568.6,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container><br><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.357ex;" xmlns="http://www.w3.org/2000/svg" width="2.034ex" height="1.357ex" role="img" focusable="false" viewBox="0 -442 899 599.8"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mi" transform="translate(605,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g></g></svg></mjx-container>表示第i个像素值，<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.294ex" height="1.025ex" role="img" focusable="false" viewBox="0 -442 572 453"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g></g></g></svg></mjx-container>表示图像x</p>
<p>然后最大化训练数据的似然(maximize likelihood of training data)</p>
<p>这是一个像素值的复杂分布，我们可以用神经网络来表示。在此之前，我们需要去定义”previous pixels”的顺序。</p>
<h3 id="PixelRNN"><a href="#PixelRNN" class="headerlink" title="PixelRNN"></a>PixelRNN</h3><p>该算法从图像的左上角像素点开始生成，像右方和下方生成，使用RNN神经网络(LSTM).</p>
<p>缺点是序列生成很慢</p>
<h3 id="PixelCNN"><a href="#PixelCNN" class="headerlink" title="PixelCNN"></a>PixelCNN</h3><p>仍然从边角处生成图片，区别是使用了CNN网络。</p>
<p>比RNN网络要快一些，但仍然很慢</p>
<h2 id="Variational-Autoencoder-VAE"><a href="#Variational-Autoencoder-VAE" class="headerlink" title="Variational Autoencoder(VAE)"></a>Variational Autoencoder(VAE)</h2><h3 id="Autoencoders"><a href="#Autoencoders" class="headerlink" title="Autoencoders"></a>Autoencoders</h3><p>通过无监督的方法从输入的数据(无标签)中学习低维的特征表示：编码(encoder)</p>
<p>编码器可以有很多中形式，通常使用神经网络</p>
<p>训练出来的特征可以用来重构原始数据：解码(decoder)</p>
<p>输入数据和输出的重构数据之间可以使用L2 loss function</p>
<p>无监督训练完成encoder后，可以使用监督训练方法训练分类器，再对encoder进行微调</p>
<h3 id="Variational-Autoencoder"><a href="#Variational-Autoencoder" class="headerlink" title="Variational  Autoencoder"></a>Variational  Autoencoder</h3><p>向自编码器(autoencoder)中加入随机因子获得的一种模型，这样我们就能从模型中采样生成新数据</p>
<p>假设训练数据是从特征表示z中生成的<br><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -1.948ex;" xmlns="http://www.w3.org/2000/svg" width="24.589ex" height="5.027ex" role="img" focusable="false" viewBox="0 -1361 10868.1 2222"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(536,-150) scale(0.707)"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g></g><g data-mml-node="mo" transform="translate(917.6,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(1306.6,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(1878.6,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(2545.4,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mo" transform="translate(3601.2,0) translate(0 1)"><path data-c="222B" d="M114 -798Q132 -824 165 -824H167Q195 -824 223 -764T275 -600T320 -391T362 -164Q365 -143 367 -133Q439 292 523 655T645 1127Q651 1145 655 1157T672 1201T699 1257T733 1306T777 1346T828 1360Q884 1360 912 1325T944 1245Q944 1220 932 1205T909 1186T887 1183Q866 1183 849 1198T832 1239Q832 1287 885 1296L882 1300Q879 1303 874 1307T866 1313Q851 1323 833 1323Q819 1323 807 1311T775 1255T736 1139T689 936T633 628Q574 293 510 -5T410 -437T355 -629Q278 -862 165 -862Q125 -862 92 -831T55 -746Q55 -711 74 -698T112 -685Q133 -685 150 -700T167 -741Q167 -789 114 -798Z"></path></g><g data-mml-node="msub" transform="translate(4711.9,0)"><g data-mml-node="mi"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(536,-150) scale(0.707)"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g></g><g data-mml-node="mo" transform="translate(5629.5,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(6018.5,0)"><path data-c="1D467" d="M347 338Q337 338 294 349T231 360Q211 360 197 356T174 346T162 335T155 324L153 320Q150 317 138 317Q117 317 117 325Q117 330 120 339Q133 378 163 406T229 440Q241 442 246 442Q271 442 291 425T329 392T367 375Q389 375 411 408T434 441Q435 442 449 442H462Q468 436 468 434Q468 430 463 420T449 399T432 377T418 358L411 349Q368 298 275 214T160 106L148 94L163 93Q185 93 227 82T290 71Q328 71 360 90T402 140Q406 149 409 151T424 153Q443 153 443 143Q443 138 442 134Q425 72 376 31T278 -11Q252 -11 232 6T193 40T155 57Q111 57 76 -3Q70 -11 59 -11H54H41Q35 -5 35 -2Q35 13 93 84Q132 129 225 214T340 322Q352 338 347 338Z"></path></g><g data-mml-node="mo" transform="translate(6483.5,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="msub" transform="translate(6872.5,0)"><g data-mml-node="mi"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(536,-150) scale(0.707)"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g></g><g data-mml-node="mo" transform="translate(7790.1,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(8179.1,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(8751.1,0) translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path></g><g data-mml-node="mi" transform="translate(9029.1,0)"><path data-c="1D467" d="M347 338Q337 338 294 349T231 360Q211 360 197 356T174 346T162 335T155 324L153 320Q150 317 138 317Q117 317 117 325Q117 330 120 339Q133 378 163 406T229 440Q241 442 246 442Q271 442 291 425T329 392T367 375Q389 375 411 408T434 441Q435 442 449 442H462Q468 436 468 434Q468 430 463 420T449 399T432 377T418 358L411 349Q368 298 275 214T160 106L148 94L163 93Q185 93 227 82T290 71Q328 71 360 90T402 140Q406 149 409 151T424 153Q443 153 443 143Q443 138 442 134Q425 72 376 31T278 -11Q252 -11 232 6T193 40T155 57Q111 57 76 -3Q70 -11 59 -11H54H41Q35 -5 35 -2Q35 13 93 84Q132 129 225 214T340 322Q352 338 347 338Z"></path></g><g data-mml-node="mo" transform="translate(9494.1,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mi" transform="translate(9883.1,0)"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mi" transform="translate(10403.1,0)"><path data-c="1D467" d="M347 338Q337 338 294 349T231 360Q211 360 197 356T174 346T162 335T155 324L153 320Q150 317 138 317Q117 317 117 325Q117 330 120 339Q133 378 163 406T229 440Q241 442 246 442Q271 442 291 425T329 392T367 375Q389 375 411 408T434 441Q435 442 449 442H462Q468 436 468 434Q468 430 463 420T449 399T432 377T418 358L411 349Q368 298 275 214T160 106L148 94L163 93Q185 93 227 82T290 71Q328 71 360 90T402 140Q406 149 409 151T424 153Q443 153 443 143Q443 138 442 134Q425 72 376 31T278 -11Q252 -11 232 6T193 40T155 57Q111 57 76 -3Q70 -11 59 -11H54H41Q35 -5 35 -2Q35 13 93 84Q132 129 225 214T340 322Q352 338 347 338Z"></path></g></g></g></svg></mjx-container></p>
<p>听不懂。。。</p>
<p>不能直接优化</p>
<p>如果放弃现实密度建模，只想获得采样的能力？</p>
<h2 id="Generative-Adversarial-Networks-GAN"><a href="#Generative-Adversarial-Networks-GAN" class="headerlink" title="Generative Adversarial Networks(GAN)"></a>Generative Adversarial Networks(GAN)</h2><p>不使用显式密度函数，取而代之的是博弈论方法：学习通过二人博弈从训练分布中生成</p>
<p>从简单分布中采样，学习从样本到训练分布的转换(transformation)，并使用神经网络来表示这种转换</p>
<h3 id="Training-GANs-Two-player-game"><a href="#Training-GANs-Two-player-game" class="headerlink" title="Training GANs: Two-player game"></a>Training GANs: Two-player game</h3><p>训练过程看作两个玩家博弈的过程</p>
<p>Generator network: 尝试通过生成看起来真实的图像来欺骗discriminator</p>
<p>Discriminator network: 尝试去辨别真实和虚假的图像</p>
<p><img src="/hexo_blog/2023/08/06/CS231N-2/image-20230730161012468.png" alt="image-20230730161012468"></p>
<p>。。。一些数学细节，听不懂</p>
<p>优点：可以生成目前最好的样本效果</p>
<p>缺点：需要很多技巧，训练起来不稳定</p>
<h1 id="14-Deep-Reinforcement-Learning"><a href="#14-Deep-Reinforcement-Learning" class="headerlink" title="14 Deep Reinforcement Learning"></a>14 Deep Reinforcement Learning</h1><p>问题：有一个代理(agent)，能够在环境中采取行动，环境能给它提供奖励信息。</p>
<p>目标：学习如何去采取行动以便获得最大的奖励</p>
<p><img src="/hexo_blog/2023/08/06/CS231N-2/image-20230730162624787.png" alt="image-20230730162624787"></p>
<p>如图，环境给代理一个状态，代理给环境行动，环境再给代理一个奖励反馈和下一个状态</p>
<h2 id="马尔可夫决策过程-Markov-Decision-Process"><a href="#马尔可夫决策过程-Markov-Decision-Process" class="headerlink" title="马尔可夫决策过程(Markov Decision Process)"></a>马尔可夫决策过程(Markov Decision Process)</h2><p>强化学习的数学表示</p>
<p>马尔可夫性(Markov property)：当前状态完全刻画了世界的状态</p>
<p>由一组元组定义：<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="13.585ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 6004.7 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(389,0)"><path data-c="1D446" d="M308 24Q367 24 416 76T466 197Q466 260 414 284Q308 311 278 321T236 341Q176 383 176 462Q176 523 208 573T273 648Q302 673 343 688T407 704H418H425Q521 704 564 640Q565 640 577 653T603 682T623 704Q624 704 627 704T632 705Q645 705 645 698T617 577T585 459T569 456Q549 456 549 465Q549 471 550 475Q550 478 551 494T553 520Q553 554 544 579T526 616T501 641Q465 662 419 662Q362 662 313 616T263 510Q263 480 278 458T319 427Q323 425 389 408T456 390Q490 379 522 342T554 242Q554 216 546 186Q541 164 528 137T492 78T426 18T332 -20Q320 -22 298 -22Q199 -22 144 33L134 44L106 13Q83 -14 78 -18T65 -22Q52 -22 52 -14Q52 -11 110 221Q112 227 130 227H143Q149 221 149 216Q149 214 148 207T144 186T142 153Q144 114 160 87T203 47T255 29T308 24Z"></path></g><g data-mml-node="mo" transform="translate(1034,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(1478.7,0)"><path data-c="1D434" d="M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z"></path></g><g data-mml-node="mo" transform="translate(2228.7,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(2673.3,0)"><path data-c="1D445" d="M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z"></path></g><g data-mml-node="mo" transform="translate(3432.3,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(3877,0)"><path data-c="1D443" d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z"></path></g><g data-mml-node="mo" transform="translate(4628,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(5072.7,0)"><path data-c="1D6FE" d="M31 249Q11 249 11 258Q11 275 26 304T66 365T129 418T206 441Q233 441 239 440Q287 429 318 386T371 255Q385 195 385 170Q385 166 386 166L398 193Q418 244 443 300T486 391T508 430Q510 431 524 431H537Q543 425 543 422Q543 418 522 378T463 251T391 71Q385 55 378 6T357 -100Q341 -165 330 -190T303 -216Q286 -216 286 -188Q286 -138 340 32L346 51L347 69Q348 79 348 100Q348 257 291 317Q251 355 196 355Q148 355 108 329T51 260Q49 251 47 251Q45 249 31 249Z"></path></g><g data-mml-node="mo" transform="translate(5615.7,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container>：</p>
<ul>
<li><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.05ex;" xmlns="http://www.w3.org/2000/svg" width="1.459ex" height="1.645ex" role="img" focusable="false" viewBox="0 -705 645 727"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D446" d="M308 24Q367 24 416 76T466 197Q466 260 414 284Q308 311 278 321T236 341Q176 383 176 462Q176 523 208 573T273 648Q302 673 343 688T407 704H418H425Q521 704 564 640Q565 640 577 653T603 682T623 704Q624 704 627 704T632 705Q645 705 645 698T617 577T585 459T569 456Q549 456 549 465Q549 471 550 475Q550 478 551 494T553 520Q553 554 544 579T526 616T501 641Q465 662 419 662Q362 662 313 616T263 510Q263 480 278 458T319 427Q323 425 389 408T456 390Q490 379 522 342T554 242Q554 216 546 186Q541 164 528 137T492 78T426 18T332 -20Q320 -22 298 -22Q199 -22 144 33L134 44L106 13Q83 -14 78 -18T65 -22Q52 -22 52 -14Q52 -11 110 221Q112 227 130 227H143Q149 221 149 216Q149 214 148 207T144 186T142 153Q144 114 160 87T203 47T255 29T308 24Z"></path></g></g></g></svg></mjx-container>：可能的状态集</li>
<li><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: 0;" xmlns="http://www.w3.org/2000/svg" width="1.697ex" height="1.62ex" role="img" focusable="false" viewBox="0 -716 750 716"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D434" d="M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z"></path></g></g></g></svg></mjx-container>：可能的行动集</li>
<li><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.048ex;" xmlns="http://www.w3.org/2000/svg" width="1.717ex" height="1.593ex" role="img" focusable="false" viewBox="0 -683 759 704"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D445" d="M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z"></path></g></g></g></svg></mjx-container>：奖励分布，用(state, action)表示</li>
<li><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: 0;" xmlns="http://www.w3.org/2000/svg" width="1.699ex" height="1.545ex" role="img" focusable="false" viewBox="0 -683 751 683"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D443" d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z"></path></g></g></g></svg></mjx-container>：转换下一个状态-行动对的可能性</li>
<li><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.489ex;" xmlns="http://www.w3.org/2000/svg" width="1.229ex" height="1.486ex" role="img" focusable="false" viewBox="0 -441 543 657"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D6FE" d="M31 249Q11 249 11 258Q11 275 26 304T66 365T129 418T206 441Q233 441 239 440Q287 429 318 386T371 255Q385 195 385 170Q385 166 386 166L398 193Q418 244 443 300T486 391T508 430Q510 431 524 431H537Q543 425 543 422Q543 418 522 378T463 251T391 71Q385 55 378 6T357 -100Q341 -165 330 -190T303 -216Q286 -216 286 -188Q286 -138 340 32L346 51L347 69Q348 79 348 100Q348 257 291 317Q251 355 196 355Q148 355 108 329T51 260Q49 251 47 251Q45 249 31 249Z"></path></g></g></g></svg></mjx-container>：折扣因子，为近期奖励和远期奖励分配权重</li>
</ul>
<p>目的：找出最佳策略集<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="2.277ex" height="1.59ex" role="img" focusable="false" viewBox="0 -691.8 1006.6 702.8"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msup"><g data-mml-node="mi"><path data-c="1D70B" d="M132 -11Q98 -11 98 22V33L111 61Q186 219 220 334L228 358H196Q158 358 142 355T103 336Q92 329 81 318T62 297T53 285Q51 284 38 284Q19 284 19 294Q19 300 38 329T93 391T164 429Q171 431 389 431Q549 431 553 430Q573 423 573 402Q573 371 541 360Q535 358 472 358H408L405 341Q393 269 393 222Q393 170 402 129T421 65T431 37Q431 20 417 5T381 -10Q370 -10 363 -7T347 17T331 77Q330 86 330 121Q330 170 339 226T357 318T367 358H269L268 354Q268 351 249 275T206 114T175 17Q164 -11 132 -11Z"></path></g><g data-mml-node="mo" transform="translate(603,363) scale(0.707)"><path data-c="2217" d="M229 286Q216 420 216 436Q216 454 240 464Q241 464 245 464T251 465Q263 464 273 456T283 436Q283 419 277 356T270 286L328 328Q384 369 389 372T399 375Q412 375 423 365T435 338Q435 325 425 315Q420 312 357 282T289 250L355 219L425 184Q434 175 434 161Q434 146 425 136T401 125Q393 125 383 131T328 171L270 213Q283 79 283 63Q283 53 276 44T250 35Q231 35 224 44T216 63Q216 80 222 143T229 213L171 171Q115 130 110 127Q106 124 100 124Q87 124 76 134T64 161Q64 166 64 169T67 175T72 181T81 188T94 195T113 204T138 215T170 230T210 250L74 315Q65 324 65 338Q65 353 74 363T98 374Q106 374 116 368T171 328L229 286Z"></path></g></g></g></g></svg></mjx-container>，最大化奖励的和</p>
<p>一些数学表达，描述问题和简单的解决问题，只记录大意</p>
<p>描述问题：</p>
<ul>
<li><p>Value function：状态好不好？</p>
</li>
<li><p>Q-value function：state-action对好不好？</p>
</li>
</ul>
<p>Bellman equation：最优的Q-value function(<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.439ex;" xmlns="http://www.w3.org/2000/svg" width="2.777ex" height="2.032ex" role="img" focusable="false" viewBox="0 -704 1227.6 898"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msup"><g data-mml-node="mi"><path data-c="1D444" d="M399 -80Q399 -47 400 -30T402 -11V-7L387 -11Q341 -22 303 -22Q208 -22 138 35T51 201Q50 209 50 244Q50 346 98 438T227 601Q351 704 476 704Q514 704 524 703Q621 689 680 617T740 435Q740 255 592 107Q529 47 461 16L444 8V3Q444 2 449 -24T470 -66T516 -82Q551 -82 583 -60T625 -3Q631 11 638 11Q647 11 649 2Q649 -6 639 -34T611 -100T557 -165T481 -194Q399 -194 399 -87V-80ZM636 468Q636 523 621 564T580 625T530 655T477 665Q429 665 379 640Q277 591 215 464T153 216Q153 110 207 59Q231 38 236 38V46Q236 86 269 120T347 155Q372 155 390 144T417 114T429 82T435 55L448 64Q512 108 557 185T619 334T636 468ZM314 18Q362 18 404 39L403 49Q399 104 366 115Q354 117 347 117Q344 117 341 117T337 118Q317 118 296 98T274 52Q274 18 314 18Z"></path></g><g data-mml-node="mo" transform="translate(824,363) scale(0.707)"><path data-c="2217" d="M229 286Q216 420 216 436Q216 454 240 464Q241 464 245 464T251 465Q263 464 273 456T283 436Q283 419 277 356T270 286L328 328Q384 369 389 372T399 375Q412 375 423 365T435 338Q435 325 425 315Q420 312 357 282T289 250L355 219L425 184Q434 175 434 161Q434 146 425 136T401 125Q393 125 383 131T328 171L270 213Q283 79 283 63Q283 53 276 44T250 35Q231 35 224 44T216 63Q216 80 222 143T229 213L171 171Q115 130 110 127Q106 124 100 124Q87 124 76 134T64 161Q64 166 64 169T67 175T72 181T81 188T94 195T113 204T138 215T170 230T210 250L74 315Q65 324 65 338Q65 353 74 363T98 374Q106 374 116 368T171 328L229 286Z"></path></g></g></g></g></svg></mjx-container>)满足Bellman equation</p>
<p>求解最优策略：Value iteration算法：使用Bellman equation作为一个迭代更新</p>
<p>问题：计算的状态空间太大，解决方案：使用函数逼近action-value function</p>
<p>最常用的函数逼近器是一个深度神经网络：deep q-learning</p>
<h3 id="Q-learning"><a href="#Q-learning" class="headerlink" title="Q-learning"></a>Q-learning</h3><p>前向传播的损失函数：bellman equation构造</p>
<p>反向传播更新参数</p>
<p>架构：</p>
<p><img src="/hexo_blog/2023/08/06/CS231N-2/image-20230730171552564.png" alt="image-20230730171552564"></p>
<p>问题：过于复杂，面对高维状态很难学习到正确的state-action对</p>
<p>比如在机器人抓举学习中，状态参数的维度很高，但策略可能很简单：抓紧！</p>
<p>因此可以直接学习策略，从一系列策略中找最好的策略：</p>
<h3 id="Policy-Gradients"><a href="#Policy-Gradients" class="headerlink" title="Policy Gradients"></a>Policy Gradients</h3><p>对每个策略，定义策略价值，最大化策略价值函数</p>
<p>各种算法及优化…略</p>
<h1 id="15-Efficient-Methods-and-Hardware-for-Deep-Learning"><a href="#15-Efficient-Methods-and-Hardware-for-Deep-Learning" class="headerlink" title="15 Efficient Methods and Hardware for Deep Learning"></a>15 Efficient Methods and Hardware for Deep Learning</h1><p>大模型难题：训练慢、难部署、能耗高 </p>
<p>因果链：更大的模型-&gt;更多的存储读取(占大头)-&gt;更多的能耗</p>
<p>如何让深度学习更有效率？通过算法和硬件的联动设计来提升效率</p>
<p>主要考虑四个方面：算法、推断、训练和硬件</p>
<p><img src="/hexo_blog/2023/08/06/CS231N-2/image-20230730184126993.png" alt="image-20230730184126993"></p>
<p>the family</p>
<p>Hardware</p>
<ul>
<li>General Purpose通用硬件<ul>
<li>CPU：延时导向(latency oriente)，单线程</li>
<li>GPU：吞吐量导向(throughput oriented)，很多小线程</li>
</ul>
</li>
<li>Specialized HW专用硬件<ul>
<li>FGPA：现场可编程门阵列(Field Programmable Gate Array)，可编程，效率不高，介于通用硬件和ASIC之间</li>
<li>ASIC：特定用途集成电路(Application Specific Integrated Circuti)，固定逻辑，专为深度学习设计，如谷歌的TPU</li>
</ul>
</li>
</ul>
<h2 id="高效推断算法-Algorithms-for-Efficient-Inference"><a href="#高效推断算法-Algorithms-for-Efficient-Inference" class="headerlink" title="高效推断算法(Algorithms for Efficient Inference)"></a>高效推断算法(Algorithms for Efficient Inference)</h2><h3 id="Pruning-剪枝"><a href="#Pruning-剪枝" class="headerlink" title="Pruning(剪枝)"></a>Pruning(剪枝)</h3><p>移除一些权值，保证准确率不变。不是所有的权值都是有用的</p>
<p>剪枝的方法：对权值进行排序，足够小的就可以删掉</p>
<h3 id="权值共享-weight-sharing"><a href="#权值共享-weight-sharing" class="headerlink" title="权值共享(weight sharing)"></a>权值共享(weight sharing)</h3><p>对于一些相近的权值，如2.09, 1.92可以统一共享2.0，既节省内存(共享+降低精度)，又防止过拟合</p>
<p>思路：将所有权重聚类，用中心点替换类中所有的权重</p>
<p>可以将剪枝和权值共享联合起来，大约能压缩到3%，不会降低准确度</p>
<p><strong>哈夫曼编码</strong>(Huffman Coding)</p>
<p>用更少的数位表示常出现的权重，用更多的数位表示不常出现的权重</p>
<p>综合这上面三种方法，大约可以将模型压缩10倍</p>
<p><strong>SqueezeNet</strong></p>
<p>直接搭建精简模型来训练。</p>
<p>主要思想是，在全卷积之前加一层1×1的压缩层(squeeze)，降低输入的维度</p>
<p>准确率和Alex差不多，但压缩后的SqeezeNet体积比Alex小了510倍!</p>
<p>优点：易部署、速度快、能耗低</p>
<h3 id="Quantization-量化"><a href="#Quantization-量化" class="headerlink" title="Quantization(量化)"></a>Quantization(量化)</h3><p>训练一个神经网络，通过统计每一层的信息，来量化权重和激活值，比如最大值，最小值，多少位数字能足以表示这个动态范围(多少位整数？多少位小数？)</p>
<p>也可以微调浮点数的格式，如用定点数前向传播，用浮点数反向传播并更新权重。</p>
<h3 id="低秩近似-Low-Rank-Approximation"><a href="#低秩近似-Low-Rank-Approximation" class="headerlink" title="低秩近似(Low Rank Approximation)"></a>低秩近似(Low Rank Approximation)</h3><p>可以将一个卷积层拆分成两步卷积，速度提升，基本不损失准确率</p>
<p>全连接层也有相似的方法，将一个权值矩阵通过奇异值分解等方法分解为多个小矩阵</p>
<h3 id="Binary-Ternary-Net-Motivation"><a href="#Binary-Ternary-Net-Motivation" class="headerlink" title="Binary/Ternary Net: Motivation"></a>Binary/Ternary Net: Motivation</h3><p>只用三个或两个权重值，效率更高，消耗更少</p>
<h3 id="Winograd-Transformation"><a href="#Winograd-Transformation" class="headerlink" title="Winograd Transformation"></a>Winograd Transformation</h3><p>先将输入矩阵映射为特征矩阵(4×4)，特征矩阵只包含3个值(1, 0.5, 2)。将卷积核转换为4×4张量，然后将特征矩阵和卷积核对应位置相乘，最后通道数c方向上相加求和(总乘法次数=16×通道数c)，做逆变换后得到输出</p>
<h2 id="高效推断硬件-Hardware-for-Efficient-Inference"><a href="#高效推断硬件-Hardware-for-Efficient-Inference" class="headerlink" title="高效推断硬件(Hardware for Efficient Inference)"></a>高效推断硬件(Hardware for Efficient Inference)</h2><p>共同的目标：减少内存访问次数</p>
<p>举例：</p>
<ul>
<li>Ryeriss: MIT, 使用RS Dataflow技术：</li>
<li>DaDiannao: CAS, 使用eDRAM技术</li>
<li>TPU: Google, 8-bit Integer，核心是巨大的乘法器，大缓存芯片(软件控制)</li>
<li>EIE: Stanford, Compression/Sparsity压缩及稀疏深度神经网络推断，只传递非0权值</li>
</ul>
<p>测量计算机体系性能的小工具：Roofline Model，测量性能瓶颈</p>
<p>TPU效果强于CPU和GPU</p>
<p>EIE能量利用效率更高</p>
<h2 id="高效训练算法-Algorithms-for-Efficient-Training"><a href="#高效训练算法-Algorithms-for-Efficient-Training" class="headerlink" title="高效训练算法(Algorithms for Efficient Training)"></a>高效训练算法(Algorithms for Efficient Training)</h2><h3 id="并行化-Parallelization"><a href="#并行化-Parallelization" class="headerlink" title="并行化(Parallelization)"></a>并行化(Parallelization)</h3><p>单芯片的性能达到瓶颈，但核数在增加</p>
<p>Data Parallel，数据并行化: 并行运行多个输入，这需要权值之间并行更新。可以将参数单独作为一个节点，多个数据输入节点向一个参数节点发送梯度更新信息</p>
<p>Model Parallel，模型并行化：将模型传给不同的处理器或不同的线程。可以将输入图像裁剪为几块，分别放入不同的节点卷积，不足是块连接处不容易处理，也可以通过特征映射等方式进行并行；对于全连接层，可以将权重矩阵分为两块，用两个线程分别处理</p>
<p>超参数并行：在不同的机器上运行不同的超参数</p>
<h3 id="混合精度训练-Mixed-Precision-with-FP16-and-FP32"><a href="#混合精度训练-Mixed-Precision-with-FP16-and-FP32" class="headerlink" title="混合精度训练(Mixed Precision with FP16 and FP32)"></a>混合精度训练(Mixed Precision with FP16 and FP32)</h3><p>16位的浮点数要比32位的节省4倍</p>
<p>使用16位进行正向传播，获得激活值，反向传播梯度，但在更新权值的时候，转换为32位</p>
<p>训练效果基本一样</p>
<h3 id="模型精馏-Model-Distillation"><a href="#模型精馏-Model-Distillation" class="headerlink" title="模型精馏(Model Distillation)"></a>模型精馏(Model Distillation)</h3><p>使用多个大型预训练的高级网络去“教”小网络</p>
<p>使用软标签(Softened label)训练，而不是硬标签。例如狗的概率是50%，猫的概率是30%…，这就是软标签，硬标签则为：狗的概率为1，其他为0</p>
<h3 id="密-疏-密训练-Dende-Sparse-Dense-training-DSD"><a href="#密-疏-密训练-Dende-Sparse-Dense-training-DSD" class="headerlink" title="密-疏-密训练(Dende-Sparse-Dense training, DSD)"></a>密-疏-密训练(Dende-Sparse-Dense training, DSD)</h3><p>将训练完的神经网络剪枝后，再加上原先的层重新训练，使模型更强大</p>
<p>DSD model zoo</p>
<h2 id="高效训练硬件-Hardware-for-Efficient-Training"><a href="#高效训练硬件-Hardware-for-Efficient-Training" class="headerlink" title="高效训练硬件(Hardware for Efficient Training)"></a>高效训练硬件(Hardware for Efficient Training)</h2><h3 id="GPUs-for-Training"><a href="#GPUs-for-Training" class="headerlink" title="GPUs for Training"></a>GPUs for Training</h3><p>计算量和存储带宽是两个决定量</p>
<p>Tensor Core：一个时钟周期完成一个4×4矩阵的乘法，专为深度学习设计</p>
<p>TPU</p>
<h1 id="16-Adversarial-Examples-and-Adversarial-Training"><a href="#16-Adversarial-Examples-and-Adversarial-Training" class="headerlink" title="16 Adversarial Examples and Adversarial Training"></a>16 Adversarial Examples and Adversarial Training</h1><p>暂时不用</p>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/hexo_blog/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/" rel="tag"># 计算机视觉</a>
              <a href="/hexo_blog/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" rel="tag"># 深度学习</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/hexo_blog/2023/08/01/CS231N-1/" rel="prev" title="CS231N笔记-上">
                  <i class="fa fa-chevron-left"></i> CS231N笔记-上
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/hexo_blog/2023/09/07/BooksManager/" rel="next" title="Java Web项目—图书管理系统">
                  Java Web项目—图书管理系统 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2023</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">xu liyi</span>
  </div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

    </div>
  </footer>

  
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/hexo_blog/js/comments.js"></script><script src="/hexo_blog/js/utils.js"></script><script src="/hexo_blog/js/motion.js"></script><script src="/hexo_blog/js/next-boot.js"></script>

  






  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/hexo_blog/js/third-party/math/mathjax.js"></script>



</body>
</html>
